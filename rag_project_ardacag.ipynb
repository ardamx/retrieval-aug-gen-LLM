{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSxWrhbevSA-"
      },
      "outputs": [],
      "source": [
        "pip install sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Generate sentence embeddings from input.txt file\n",
        "2.   Saving embeddings to a FAISS Index Vector Store\n",
        "3.   Save sentences to a file to keep track of the order"
      ],
      "metadata": {
        "id": "ALEaQiZf6Sqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Function to read sentences from a text file\n",
        "def read_sentences_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        sentences = file.readlines()\n",
        "    # Strip newline characters\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "    return sentences\n",
        "\n",
        "# Path to your text file\n",
        "file_path = 'input.txt'\n",
        "\n",
        "# Read sentences from the file\n",
        "sentences = read_sentences_from_file(file_path)\n",
        "\n",
        "# Load a pre-trained Sentence Transformers model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "\n",
        "# Print embeddings\n",
        "#for i, embedding in enumerate(embeddings):\n",
        "#    print(f\"Sentence {i+1}: {sentences[i]}\")\n",
        "#    print(f\"Embedding: {embedding}\\n\")\n",
        "\n",
        "\n",
        "# Initialize FAISS index\n",
        "dimension = embeddings.shape[1]  # Dimension of the embeddings\n",
        "index = faiss.IndexFlatL2(dimension)  # Build the index\n",
        "index.add(np.array(embeddings))  # Add embeddings to the index\n",
        "\n",
        "# Save FAISS index\n",
        "faiss.write_index(index, \"embeddings.index\")\n",
        "\n",
        "# Save sentences to a file to keep track of the order\n",
        "with open('sentences.txt', 'w', encoding='utf-8') as file:\n",
        "    for sentence in sentences:\n",
        "        file.write(f\"{sentence}\\n\")\n"
      ],
      "metadata": {
        "id": "qB6OdJQcvV20"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Load the FAISS index\n",
        "2.   Query\n",
        "3.   Construct the context\n",
        "4.   Get an answer from the LLM"
      ],
      "metadata": {
        "id": "h4rMOSDbOMid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(\"embeddings.index\")\n",
        "\n",
        "# Function to read sentences from a text file\n",
        "def read_sentences_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        sentences = file.readlines()\n",
        "    # Strip newline characters\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "    return sentences\n",
        "\n",
        "# Load the sentences\n",
        "sentences = read_sentences_from_file('sentences.txt')\n",
        "\n",
        "# Load the same pre-trained Sentence Transformers model used before\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Load a pre-trained Hugging Face model for text generation\n",
        "text_generation_pipeline = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\")\n",
        "\n",
        "# Function to query the FAISS index and construct the context\n",
        "def construct_context(query, k=5):\n",
        "    # Generate the embedding for the query\n",
        "    query_embedding = model.encode([query])\n",
        "\n",
        "    # Search the index\n",
        "    distances, indices = index.search(np.array(query_embedding), k)\n",
        "\n",
        "    # Retrieve the top k similar sentences\n",
        "    relevant_sentences = [sentences[idx] for idx in indices[0]]\n",
        "\n",
        "    # Construct the context\n",
        "    context = \"\\n\".join(relevant_sentences)\n",
        "    return context\n",
        "\n",
        "# Function to generate an answer from the context using the language model\n",
        "def generate_answer_from_lm(context):\n",
        "    answer = text_generation_pipeline(context, max_length=50, do_sample=False)[0]['generated_text']\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "9bbjA2cB-JTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Adieu\" #max 50 chars\n",
        "context = construct_context(query)\n",
        "answer = generate_answer_from_lm(context)\n",
        "\n",
        "print(\"Context:\\n\", context)\n",
        "print(\"\\nAnswer:\\n\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZV9jlm5BZqN",
        "outputId": "7b099e59-32aa-43da-d5e1-67ba32710af1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            " Adieu, sir.\n",
            "Good sir, adieu.\n",
            "Adieu, good neighbour.\n",
            "Adieu, poor soul, that takest thy leave of it!\n",
            "Father, and wife, and gentlemen, adieu;\n",
            "\n",
            "Answer:\n",
            " Adieu, sir.\n",
            "Good sir, adieu.\n",
            "Adieu, good neighbour.\n",
            "Adieu, poor soul, that takest thy leave of it!\n",
            "Father, and wife, and gentlemen, adieu;\n",
            "And,\n"
          ]
        }
      ]
    }
  ]
}